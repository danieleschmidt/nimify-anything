# Nimify Anything - Environment Configuration Template
# Copy to .env and fill in your specific values

# =============================================================================
# CORE APPLICATION SETTINGS
# =============================================================================

# Application environment (development, staging, production)
NIMIFY_ENV=development

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Application port for development server
APP_PORT=8000

# =============================================================================
# NVIDIA NIM CONFIGURATION
# =============================================================================

# NVIDIA NGC API Key (required for pulling NIM containers)
# Get from: https://catalog.ngc.nvidia.com/
NGC_API_KEY=your_ngc_api_key_here

# NVIDIA NIM Registry URL
NIM_REGISTRY=nvcr.io/nim

# Default NIM runtime version
NIM_VERSION=24.11

# =============================================================================
# KUBERNETES CONFIGURATION
# =============================================================================

# Kubernetes context to use for deployments
KUBECONFIG_CONTEXT=docker-desktop

# Default namespace for nimify deployments
NIMIFY_NAMESPACE=nimify-system

# Kubernetes cluster type (eks, gke, aks, kind, minikube, other)
K8S_CLUSTER_TYPE=kind

# =============================================================================
# CONTAINER REGISTRY SETTINGS
# =============================================================================

# Container registry for built images
CONTAINER_REGISTRY=localhost:5000

# Registry username (if authentication required)
REGISTRY_USERNAME=

# Registry password (if authentication required)
REGISTRY_PASSWORD=

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================

# Prometheus endpoint for metrics scraping
PROMETHEUS_ENDPOINT=http://localhost:9090

# Grafana endpoint for dashboards
GRAFANA_ENDPOINT=http://localhost:3000

# OpenTelemetry collector endpoint
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Enable distributed tracing
ENABLE_TRACING=true

# =============================================================================
# CLOUD PROVIDER SETTINGS
# =============================================================================

# AWS Configuration
AWS_REGION=us-west-2
AWS_PROFILE=default

# Google Cloud Configuration
GOOGLE_PROJECT_ID=your-project-id
GOOGLE_REGION=us-central1-a

# Azure Configuration
AZURE_SUBSCRIPTION_ID=your-subscription-id
AZURE_RESOURCE_GROUP=nimify-rg
AZURE_LOCATION=eastus

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Enable debug mode (verbose logging, hot reload)
DEBUG=true

# Skip GPU requirements for local development
SKIP_GPU_CHECK=true

# Mock external services for testing
MOCK_SERVICES=false

# Development model repository path
DEV_MODEL_REPO=/tmp/nimify-models

# =============================================================================
# SECURITY SETTINGS
# =============================================================================

# Enable security scanning of containers
SECURITY_SCAN_ENABLED=true

# SBOM generation
GENERATE_SBOM=true

# Sign container images
SIGN_IMAGES=false

# Cosign private key path (if signing enabled)
COSIGN_PRIVATE_KEY=

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# Default GPU memory limit (e.g., 8Gi, 16Gi)
DEFAULT_GPU_MEMORY=8Gi

# Default CPU limit (e.g., 2, 4, 8)
DEFAULT_CPU_LIMIT=4

# Default memory limit (e.g., 8Gi, 16Gi)
DEFAULT_MEMORY_LIMIT=8Gi

# Maximum batch size for model inference
MAX_BATCH_SIZE=32

# Model cache directory
MODEL_CACHE_DIR=/tmp/nimify-cache

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================

# Enable experimental features (may be unstable)
ENABLE_EXPERIMENTAL=false

# Enable A/B testing framework
ENABLE_AB_TESTING=false

# Enable multi-model serving
ENABLE_ENSEMBLE=false

# =============================================================================
# THIRD-PARTY INTEGRATIONS
# =============================================================================

# Slack webhook for notifications
SLACK_WEBHOOK_URL=

# Discord webhook for notifications
DISCORD_WEBHOOK_URL=

# MLflow tracking server
MLFLOW_TRACKING_URI=

# Weights & Biases project
WANDB_PROJECT=

# Hugging Face Hub token
HUGGINGFACE_TOKEN=

# =============================================================================
# TESTING CONFIGURATION
# =============================================================================

# Test model repository
TEST_MODEL_REPO=tests/fixtures/models

# Enable integration tests (requires cluster access)
RUN_INTEGRATION_TESTS=false

# Test timeout in seconds
TEST_TIMEOUT=300

# Load test configuration
LOAD_TEST_USERS=10
LOAD_TEST_DURATION=60s